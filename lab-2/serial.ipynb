{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = r'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET_FILTER_5HZ_SET_GYRO_250_SET_ACC_2G\n",
    "# SET_FILTER_5HZ_SET_GYRO_500_SET_ACC_4G_0\n",
    "# SET_FILTER_5HZ_SET_GYRO_1000_SET_ACC_8G_0\n",
    "# SET_FILTER_5HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "\n",
    "# SET_FILTER_10HZ_SET_GYRO_250_SET_ACC_2G_0\n",
    "# SET_FILTER_10HZ_SET_GYRO_500_SET_ACC_4G_0\n",
    "# SET_FILTER_10HZ_SET_GYRO_1000_SET_ACC_8G_0\n",
    "# SET_FILTER_10HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_21HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_44HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_94HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_184HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_260HZ_SET_GYRO_2000_SET_ACC_16G_0\n",
    "\n",
    "# SET_FILTER_21HZ_SET_GYRO_1000_SET_ACC_8G_0\n",
    "# SET_FILTER_44HZ_SET_GYRO_500_SET_ACC_8G_0\n",
    "\n",
    "# SET_FILTER_21HZ_SET_GYRO_500_SET_ACC_4G_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser = serial.Serial('COM3', 115200, timeout=1)\n",
    "# linesToRead = 1000\n",
    "# data = []\n",
    "# for i in range(0, linesToRead):\n",
    "#     try:\n",
    "#         line = ser.readline().decode('utf-8')\n",
    "#         data.append(line)\n",
    "#         print(line)\n",
    "#     except:\n",
    "#         print(\"Error reading from serial port\")\n",
    "#         continue\n",
    "# ser.close()\n",
    "\n",
    "# data_arr = []\n",
    "\n",
    "# for line in data:\n",
    "#     try:\n",
    "#         data_arr.append(json.loads(line))\n",
    "#     except:\n",
    "#         continue\n",
    "# #load all json data into a dataframe\n",
    "# df = pd.json_normalize(data_arr)\n",
    "# display(df)\n",
    "\n",
    "filename = input(\"Enter filename: \")\n",
    "for k in range(3):\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    ser = serial.Serial('COM3', 115200, timeout=1)\n",
    "    linesToRead = 1000\n",
    "    data = []\n",
    "    for i in range(0, linesToRead):\n",
    "        try:\n",
    "            line = ser.readline().decode('utf-8')\n",
    "            data.append(line)\n",
    "            print(line)\n",
    "        except:\n",
    "            print(\"Error reading from serial port\")\n",
    "            continue\n",
    "    ser.close()\n",
    "\n",
    "    data_arr = []\n",
    "    \n",
    "    for line in data:\n",
    "        try:\n",
    "            data_arr.append(json.loads(line))\n",
    "        except:\n",
    "            continue\n",
    "        #load all json data into a dataframe\n",
    "        df = pd.json_normalize(data_arr)\n",
    "        display(df)\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        df.to_csv(os.path.join(result_dir, filename + '_' + str(k) + '.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (71, 1), indices imply (71, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#make a table of files\u001b[39;00m\n\u001b[0;32m      2\u001b[0m files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mlistdir(result_dir)\n\u001b[1;32m----> 3\u001b[0m df_f \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(files, columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mfilename\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfilter\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mgyro\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39macc\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[0;32m      5\u001b[0m     \u001b[39m#SET_FILTER_260HZ_SET_GYRO_2000_SET_ACC_16G_2.csv\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:762\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    754\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    755\u001b[0m             arrays,\n\u001b[0;32m    756\u001b[0m             columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    759\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    760\u001b[0m         )\n\u001b[0;32m    761\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 762\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    763\u001b[0m             data,\n\u001b[0;32m    764\u001b[0m             index,\n\u001b[0;32m    765\u001b[0m             columns,\n\u001b[0;32m    766\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    767\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    768\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    769\u001b[0m         )\n\u001b[0;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    772\u001b[0m         {},\n\u001b[0;32m    773\u001b[0m         index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    776\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    777\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (71, 1), indices imply (71, 4)"
     ]
    }
   ],
   "source": [
    "#make a table of files\n",
    "files = os.listdir(result_dir)\n",
    "df_f = pd.DataFrame(files, columns=['filename', 'filter', 'gyro', 'acc'])\n",
    "for file in files:\n",
    "    #SET_FILTER_260HZ_SET_GYRO_2000_SET_ACC_16G_2.csv\n",
    "    if file.endswith('.csv'):\n",
    "        name = file.split('.')[0]\n",
    "        filter = name.split('_')[2]\n",
    "        gyro = name.split('_')[4]\n",
    "        acc = name.split('_')[6]\n",
    "        df_f = pd.concat([df_f, pd.DataFrame([[file, filter, gyro, acc]], columns=['filename', 'filter', 'gyro', 'acc'])])\n",
    "\n",
    "display(df_f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tittle = filename\n",
    "output_f = result_dir + '/' + input_tittle\n",
    "if not os.path.exists(output_f):\n",
    "    os.makedirs(output_f)\n",
    "#show acceleration data acc_X, acc_Y, acc_Z\n",
    "fig = px.line(df, x=df.index, y=['acc_X', 'acc_Y', 'acc_Z'])\n",
    "fig.update_layout(title='Acceleration data - ' + input_tittle , xaxis_title='reading count', yaxis_title='Acceleration int16')\n",
    "fig.show()\n",
    "fig.write_html(output_f + '/acc.html')\n",
    "iter = ['acc_X', 'acc_Y', 'acc_Z']\n",
    "df_avg = df[iter].mean()\n",
    "fig = px.bar(df_avg, x=df_avg.index, y=df_avg)\n",
    "fig.update_layout(title='Acceleration data - ' + input_tittle + ' average', xaxis_title='axis', yaxis_title='Acceleration int16')\n",
    "fig.show()\n",
    "fig.write_html(output_f + '/acc_avg.html')\n",
    "for i in iter:\n",
    "    title_d = 'Acceleration data - ' + input_tittle + 'axis: ' +  i\n",
    "    fig = px.line(df, x=df.index, y=i)\n",
    "    fig.update_layout(title=title_d, xaxis_title='reading count', yaxis_title='Acceleration int16')\n",
    "    fig.show()\n",
    "    fig.write_html(output_f + '/' + i + '.html')\n",
    "    fig = px.histogram(df, x=i)\n",
    "    fig.update_layout(title=title_d +  i, xaxis_title='Acceleration int16', yaxis_title='count')\n",
    "    fig.show()\n",
    "    fig.write_html(output_f + '/' + i + '_hist.html')\n",
    "#show gyroscope data gyro_X, gyro_Y, gyro_Z\n",
    "fig = px.line(df, x=df.index, y=['gyr_X', 'gyr_Y', 'gyr_Z'])\n",
    "fig.update_layout(title='Gyroscope data - ' + input_tittle , xaxis_title='reading count', yaxis_title='Gyroscope int16')\n",
    "fig.show()\n",
    "fig.write_html(output_f + '/gyro.html')\n",
    "iter = ['gyr_X', 'gyr_Y', 'gyr_Z']\n",
    "for i in iter:\n",
    "    title_d = 'Gyroscope data - ' + input_tittle + 'axis: ' +  i\n",
    "    fig = px.line(df, x=df.index, y=i)\n",
    "    fig.update_layout(title=title_d, xaxis_title='reading count', yaxis_title='Gyroscope int16')\n",
    "    fig.show()\n",
    "    fig.write_html(output_f + '/' + i + '.html')\n",
    "    fig = px.histogram(df, x=i)\n",
    "    fig.update_layout(title=title_d +  i, xaxis_title='Gyroscope int16', yaxis_title='count')\n",
    "    fig.show()\n",
    "    fig.write_html(output_f + '/' + i + '_hist.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a histogram\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "figures = []\n",
    "for col in df.columns:\n",
    "    fig = px.histogram(df, x=col)\n",
    "    fig.update_layout(title_text=col)\n",
    "    figures.append(fig)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "import os, sys\n",
    "\n",
    "df = pd.read_csv(\"NewFile2.csv\")\n",
    "\"3.32e+00,3.32e+00,\"\n",
    "#replace all e+ to float\n",
    "df['CH1'] = df['CH1'].str.replace('e+', 'E')\n",
    "df['CH2'] = df['CH2'].str.replace('e+', 'E')\n",
    "display(df)\n",
    "\n",
    "#plot chanel ch1 and ch2\n",
    "fig = px.line(df, x=df.index, y=[\"CH1\"])\n",
    "fig.show()\n",
    "fig = px.line(df, x=df.index, y=[\"CH2\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
